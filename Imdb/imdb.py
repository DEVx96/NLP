# -*- coding: utf-8 -*-
"""imdb.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SQLV0Uc-lAEgnxD1vwQEZv7qeOmuthJS
"""

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext autoreload
# %autoreload 2
# %matplotlib inline

from fastai import *
from fastai.text import *

path = untar_data(URLs.IMDB)
path.ls()

"""Mounting Drive since training takes and long time and runtime may disconnect.This step is not required if code is run locally"""

from google.colab import drive
drive.mount('/content/gdrive',force_remount=True)

bs = 48
data_lm = TextList.from_folder(path).filter_by_folder(['train','test','unsup']).split_by_rand_pct(0.1).label_for_lm().databunch(bs=bs)

data_lm.save('data_lm')

save_dir = Path('/content/gdrive/My Drive/Colab Notebooks/imdb')
save_dir.mkdir(exist_ok = True,parents=True)

cp -rf /root/.fastai/data/imdb/data_* /content/gdrive/My\ Drive/Colab\ Notebooks/imdb/

data_lm.show_batch(3)

data_lm.vocab.itos[:5]

learn_lm = language_model_learner(data_lm,AWD_LSTM,drop_mult=0.25)

learn_lm.lr_find()
learn_lm.recorder.plot(skip_end=15)

learn_lm.fit_one_cycle(2,1e-02,moms=(0.8,0.7))

"""Saving progress"""

learn_lm.save('learn_lm')
cp -rf /root/.fastai/data/imdb/mod* /content/gdrive/My\ Drive/Colab\ Notebooks/imdb/

learn_lm.load('learn_lm')
learn_lm.unfreeze()

learn_lm.unfreeze()
learn_lm.lr_find()
learn_lm.recorder.plot(skip_end=15)

learn_lm.fit_one_cycle(2,3e-03,moms=(0.8,0.7))

learn_lm.save('temp')

cp -rf /root/.fastai/data/imdb/models/temp.pth /content/gdrive/My\ Drive/Colab\ Notebooks/imdb/models/

learn_lm.fit_one_cycle(2,3e-03,moms=(0.8,0.7))

learn_lm.save('temp')

cp -rf /root/.fastai/data/imdb/models/temp.pth /content/gdrive/My\ Drive/Colab\ Notebooks/imdb/models/

learn_lm.load('temp')

learn_lm.fit_one_cycle(2)

learn_lm.save('temp')

cp -rf /root/.fastai/data/imdb/models/temp.pth /content/gdrive/My\ Drive/Colab\ Notebooks/imdb/models/

learn_lm.fit_one_cycle(2,moms=(0.8,0.7))

learn_lm.save('Learn_lm')

cp -rf /root/.fastai/data/imdb/models/Learn_lm.pth /content/gdrive/My\ Drive/Colab\ Notebooks/imdb/models/

#prediction

N_words = 20
N_sentences = 3
sentence = 'The movie was exhausting to watch'

print("\n".join(learn_lm.predict(sentence,N_words,temperature=0.7) for _ in range(N_sentences)))

learn_lm.save_encoder('learn-enc')

data_cls = TextList.from_folder(path).split_by_folder(valid='test').label_from_folder(classes=['neg','pos']).databunch(bs=48)

data_cls.show_batch(3)

data_cls.save('data_cls')

cp -rf /root/.fastai/data/imdb/data_cls* /content/gdrive/My\ Drive/Colab\ Notebooks/imdb/

learn_cls = text_classifier_learner(data_cls,AWD_LSTM,drop_mult=0.5)
learn_cls.load_encoder('learn-enc')

learn_cls.lr_find()

learn_cls.recorder.plot()

learn_cls.fit_one_cycle(1,2e-02,moms = (0.8,0.7))

learn_cls.freeze_to(-2)
learn_cls.lr_find()
learn_cls.recorder.plot()

learn_cls.fit_one_cycle(1,slice(1e-02/(2.6**4),1e-02),moms=(0.7,0.8))

learn_cls.freeze_to(-3)
learn_cls.lr_find()
learn_cls.recorder.plot()

learn_cls.fit_one_cycle(1,slice(5e-03/(2.6**4),5e-03),moms=(0.8,0.7))

learn_cls.unfreeze()
learn_cls.lr_find()
learn_cls.recorder.plot()

learn_cls.save('Pre-Final')

learn_cls.unfreeze()

learn_cls.fit_one_cycle(2,slice(3e-03/(2.6**4),3e-03),moms=(0.7,0.8))

learn_cls.summary()

interp = ClassificationInterpretation.from_learner(learn)

data_cls.valid_ds[7437]

learn.predict(data_cls.valid_ds[7437])